{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import glob\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import cv2\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy.spatial import cKDTree as KDTree\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit\n",
    "def cylindrical_projection(x, f):\n",
    "    canvas = np.zeros_like(x)\n",
    "    h, w = x.shape[:2]\n",
    "    cx, cy = w//2, h//2\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            ci = i-cy\n",
    "            cj = j-cx\n",
    "            ii = int(np.round(f*ci/np.sqrt(cj**2 + f**2) + cy))\n",
    "            jj = int(np.round(f*np.arctan2(cj,f) + cx))\n",
    "            if 0 <= ii < h and 0 <= jj < w:\n",
    "                canvas[ii, jj] = x[i, j]\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "class SIFTDescriptor(object):\n",
    "    \"\"\"Class for computing SIFT descriptor of the square patch\n",
    "\n",
    "    Attributes:\n",
    "        patchSize: size of the patch in pixels \n",
    "        maxBinValue: maximum descriptor element after L2 normalization. All above are clipped to this value\n",
    "        numOrientationBins: number of orientation bins for histogram\n",
    "        numSpatialBins: number of spatial bins. The final descriptor size is numSpatialBins x numSpatialBins x numOrientationBins\n",
    "    \"\"\"\n",
    "    def precomputebins(self):\n",
    "        halfSize = int(self.patchSize/2)\n",
    "        ps = self.patchSize\n",
    "        sb = self.spatialBins;\n",
    "        step = float(self.spatialBins + 1) / (2 * halfSize)\n",
    "        precomp_bins = np.zeros(2*ps, dtype = np.int32)\n",
    "        precomp_weights = np.zeros(2*ps, dtype = np.float)\n",
    "        precomp_bin_weights_by_bx_py_px_mapping = np.zeros((sb,sb,ps,ps), dtype = np.float)\n",
    "        for i in range(ps):\n",
    "            i1 = i + ps\n",
    "            x = step * i\n",
    "            xi = int(x)\n",
    "            # bin indices\n",
    "            precomp_bins[i] = xi -1;\n",
    "            precomp_bins[i1] = xi\n",
    "            #bin weights\n",
    "            precomp_weights[i1] = x - xi;\n",
    "            precomp_weights[i] = 1.0 - precomp_weights[i1];\n",
    "            #truncate \n",
    "            if  (precomp_bins[i] < 0):\n",
    "                precomp_bins[i] = 0;\n",
    "                precomp_weights[i] = 0\n",
    "            if  (precomp_bins[i] >= self.spatialBins):\n",
    "                precomp_bins[i] = self.spatialBins - 1;\n",
    "                precomp_weights[i] = 0\n",
    "            if  (precomp_bins[i1] < 0):\n",
    "                precomp_bins[i1] = 0;\n",
    "                precomp_weights[i1] = 0\n",
    "            if  (precomp_bins[i1] >= self.spatialBins):\n",
    "                precomp_bins[i1] = self.spatialBins - 1;\n",
    "                precomp_weights[i1] = 0\n",
    "        for y in range(ps):\n",
    "            for x in range(ps):\n",
    "                precomp_bin_weights_by_bx_py_px_mapping[precomp_bins[y], precomp_bins[x], y, x ] += precomp_weights[y]*precomp_weights[x]\n",
    "                precomp_bin_weights_by_bx_py_px_mapping[precomp_bins[y+ps], precomp_bins[x], y, x ] += precomp_weights[y+ps]*precomp_weights[x]\n",
    "                precomp_bin_weights_by_bx_py_px_mapping[precomp_bins[y], precomp_bins[x+ps], y, x ] += precomp_weights[y]*precomp_weights[x+ps]\n",
    "                precomp_bin_weights_by_bx_py_px_mapping[precomp_bins[y+ps], precomp_bins[x+ps], y, x ] += precomp_weights[y+ps]*precomp_weights[x+ps]\n",
    "        if self.mask_type == 'CircularGauss':\n",
    "            mask = self.CircularGaussKernel(kernlen=self.patchSize, circ=True, sigma_type=self.sigma_type).astype(np.float32)\n",
    "        elif self.mask_type == 'Gauss':\n",
    "            mask = self.CircularGaussKernel(kernlen=self.patchSize, circ=False, sigma_type=self.sigma_type).astype(np.float32)\n",
    "        else:\n",
    "            raise ValueError(masktype, 'is unknown mask type')\n",
    "\n",
    "        for y in range(sb):\n",
    "            for x in range(sb):\n",
    "                precomp_bin_weights_by_bx_py_px_mapping[y,x,:,:] *= mask\n",
    "                precomp_bin_weights_by_bx_py_px_mapping[y,x,:,:] = np.maximum(0,precomp_bin_weights_by_bx_py_px_mapping[y,x,:,:])\n",
    "        return precomp_bins.astype(np.int32),precomp_weights,precomp_bin_weights_by_bx_py_px_mapping,mask\n",
    "    def __repr__(self):\n",
    "            return self.__class__.__name__ + '(' + 'orientationBins=' + str(self.orientationBins) +\\\n",
    "             ', ' + 'spatialBins=' + str(self.spatialBins) +\\\n",
    "             ', ' + 'patchSize=' + str(self.patchSize) +\\\n",
    "             ', ' + 'sigma_type=' + str(self.sigma_type) +\\\n",
    "             ', ' + 'mask_type=' + str(self.mask_type) +\\\n",
    "             ', ' + 'maxBinValue=' + str(self.maxBinValue) + ')'\n",
    "\n",
    "    def __init__(self, patchSize = 41,\n",
    "                 maxBinValue = 0.2,\n",
    "                 numOrientationBins = 8,\n",
    "                 numSpatialBins = 4,\n",
    "                 mask_type = 'CircularGauss',\n",
    "                 sigma_type = 'hesamp'):\n",
    "        self.patchSize = patchSize\n",
    "        self.maxBinValue = maxBinValue\n",
    "        self.orientationBins = numOrientationBins\n",
    "        self.spatialBins = numSpatialBins\n",
    "        self.mask_type = mask_type\n",
    "        self.sigma_type = sigma_type\n",
    "        self.precomp_bins,self.precomp_weights,self.mapping,self.mask = self.precomputebins()\n",
    "        self.binaryMask = self.mask > 0\n",
    "        self.gx = np.zeros((patchSize,patchSize), dtype=np.float)\n",
    "        self.gy = np.zeros((patchSize,patchSize), dtype=np.float)\n",
    "        self.ori = np.zeros((patchSize,patchSize), dtype=np.float)\n",
    "        self.mag = np.zeros((patchSize,patchSize), dtype=np.float)\n",
    "        self.norm_patch = np.zeros((patchSize,patchSize), dtype=np.float)\n",
    "        ps = self.patchSize\n",
    "        sb = self.spatialBins\n",
    "        ob = self.orientationBins\n",
    "        self.desc = np.zeros((ob, sb , sb ), dtype = np.float)\n",
    "        return\n",
    "    def CircularGaussKernel(self,kernlen=21, circ = True, sigma_type = 'hesamp'):\n",
    "        halfSize = float(kernlen) / 2.;\n",
    "        r2 = float(halfSize**2);\n",
    "        if sigma_type == 'hesamp':\n",
    "            sigma_mul_2 = 0.9 * r2;\n",
    "        elif sigma_type == 'vlfeat':\n",
    "            sigma_mul_2 = kernlen**2\n",
    "        else:\n",
    "            raise ValueError('Unknown sigma_type', sigma_type, 'try hesamp or vlfeat')\n",
    "        disq = 0;\n",
    "        kernel = np.zeros((kernlen,kernlen))\n",
    "        for y in range(kernlen):\n",
    "            for x in range(kernlen):\n",
    "                disq = (y - halfSize+0.5)**2 +  (x - halfSize+0.5)**2;\n",
    "                kernel[y,x] = math.exp(-disq / sigma_mul_2)\n",
    "                if circ and (disq >= r2):\n",
    "                    kernel[y,x] = 0.\n",
    "        return kernel\n",
    "    def photonorm(self, patch, binaryMask = None):\n",
    "        if binaryMask is not None:\n",
    "            std1_coef = 50. /  max(np.std(patch[binaryMask]), 1e-8)\n",
    "            mean1 =  np.mean(patch[binaryMask])\n",
    "        else:\n",
    "            std1_coef = 50. / max(np.std(patch), 1e-8)\n",
    "            mean1 =  np.mean(patch)\n",
    "        if std1_coef >= 50. / 0.000001:\n",
    "            std1_coef = 50.0\n",
    "        self.norm_patch = 128. + std1_coef * (patch - mean1);\n",
    "        self.norm_patch = np.clip(self.norm_patch, 0.,255.);\n",
    "        return\n",
    "    def getDerivatives(self,image):\n",
    "        #[-1 1] kernel for borders\n",
    "        self.gx[:,0] = image[:,1] - image[:,0]\n",
    "        self.gy[0,:] = image[1,:] - image[0,:]\n",
    "        self.gx[:,-1] = image[:,-1] - image[:,-2]\n",
    "        self.gy[-1,:] = image[-1,:] - image[-2,:]\n",
    "        #[-1 0 1] kernel for the rest\n",
    "        self.gy[1:-2,:] = image[2:-1,:] - image[0:-3,:]\n",
    "        self.gx[:,1:-2] = image[:,2:-1] - image[:,0:-3]\n",
    "        self.gx *= 0.5\n",
    "        self.gy *= 0.5\n",
    "        return\n",
    "    def samplePatch(self,grad,ori):\n",
    "        ps = self.patchSize\n",
    "        sb = self.spatialBins\n",
    "        ob = self.orientationBins\n",
    "        o_big = float(ob) * (ori + 2.0*math.pi) / (2.0 * math.pi)\n",
    "        bo0_big = np.floor(o_big)#.astype(np.int32)\n",
    "        wo1_big = o_big - bo0_big;\n",
    "        bo0_big = bo0_big % ob;\n",
    "        bo1_big = (bo0_big + 1.0) % ob;\n",
    "        wo0_big = 1.0 - wo1_big;\n",
    "        wo0_big *= grad;\n",
    "        wo0_big = np.maximum(0, wo0_big)\n",
    "        wo1_big *= grad;\n",
    "        wo1_big = np.maximum(0, wo1_big)\n",
    "        ori_weight_map = np.zeros((ob,ps,ps))\n",
    "        for o in range(ob):\n",
    "            relevant0 = np.where(bo0_big == o)\n",
    "            ori_weight_map[o, relevant0[0], relevant0[1]] = wo0_big[relevant0[0], relevant0[1]]\n",
    "            relevant1 = np.where(bo1_big == o)\n",
    "            ori_weight_map[o, relevant1[0], relevant1[1]] += wo1_big[relevant1[0], relevant1[1]]\n",
    "        for y in range(sb):\n",
    "            for x in range(sb):\n",
    "                self.desc[:,y,x] =  np.tensordot( ori_weight_map, self.mapping[y,x,:,:])\n",
    "        return\n",
    "    def describe(self,patch, userootsift = False, flatten = True, show_timings = False):\n",
    "        t = time.time()\n",
    "        self.photonorm(patch, binaryMask = self.binaryMask);\n",
    "        if show_timings:\n",
    "            print( 'photonorm time = ', time.time() - t)\n",
    "            t = time.time()\n",
    "        self.getDerivatives(self.norm_patch)\n",
    "        if show_timings:\n",
    "            print( 'gradients time = ', time.time() - t)\n",
    "            t = time.time()\n",
    "        self.mag = np.sqrt(self.gx * self.gx + self.gy*self.gy)\n",
    "        self.ori = np.arctan2(self.gy,self.gx)\n",
    "        if show_timings:\n",
    "            print( 'mag + ori time = ', time.time() - t)\n",
    "            t = time.time()\n",
    "        self.samplePatch(self.mag,self.ori)\n",
    "        if show_timings:\n",
    "            print( 'sample patch time = ', time.time() - t)\n",
    "            t = time.time()\n",
    "        self.desc /= np.clip(np.linalg.norm(self.desc.flatten(),2), 1e-8, np.inf)\n",
    "        self.desc = np.clip(self.desc, 0,self.maxBinValue)\n",
    "        self.desc /= np.clip(np.linalg.norm(self.desc.flatten(),2), 1e-8, np.inf)\n",
    "        if userootsift:\n",
    "            self.desc = np.sqrt(self.desc / np.clip(np.linalg.norm(unnorm_desc.flatten(),1), 1e-8, np.inf))\n",
    "        if show_timings:\n",
    "            print( 'clip and norm time = ', time.time() - t)\n",
    "            t = time.time()\n",
    "        if flatten:\n",
    "            return np.clip(512. * self.desc.flatten() , 0, 255).astype(np.int32);\n",
    "        else:\n",
    "            return np.clip(512. * self.desc , 0, 255).astype(np.int32);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harris_response(img, window_size=(3,3), k=0.04):\n",
    "    h, w = img.shape[:2]\n",
    "    gray = img if len(img.shape)==2 else cv2.cvtColor(img.astype(np.float64), cv2.COLOR_BGR2GRAY)\n",
    "    gray = gray.astype(np.float64)\n",
    "    Ix = cv2.Sobel(gray,cv2.CV_64F,1,0)\n",
    "    Iy = cv2.Sobel(gray,cv2.CV_64F,0,1)\n",
    "    Ixx = Ix*Ix\n",
    "    Iyy = Iy*Iy\n",
    "    Ixy = Ix*Iy\n",
    "    gIxx = cv2.GaussianBlur(Ixx,window_size,0) # (H, W)\n",
    "    gIyy = cv2.GaussianBlur(Iyy,window_size,0) # (H, W)\n",
    "    gIxy = cv2.GaussianBlur(Ixy,window_size,0) # (H, W)\n",
    "    Mxy   = np.dstack([gIxx, gIxy, gIxy, gIyy])\n",
    "    Mxy   = Mxy.reshape(h, w, 2, 2)\n",
    "    Mxy_f = Mxy.reshape(-1, 2, 2)\n",
    "    detM = np.linalg.det(Mxy_f) # (H, W)\n",
    "    traceM = np.trace(Mxy_f, axis1=1, axis2=2) # (H, W)\n",
    "    R = detM - k*np.power(traceM,2)\n",
    "    return R.reshape(h, w)\n",
    "\n",
    "def detect_corner(R, num_peaks=500, radius=30, threshold=10000000):\n",
    "    coordinates = peak_local_max(R, min_distance=radius, \n",
    "                                 num_peaks=num_peaks, \n",
    "                                 threshold_abs=threshold,\n",
    "                                 exclude_border=False,\n",
    "                                 indices=True\n",
    "                                )[:,::-1]\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_blending_map(shape, f, blend_r=0.1):\n",
    "    x = cylindrical_projection(np.full(shape, 255), f)\n",
    "    h, w = shape[:2]\n",
    "    cx, cy = w//2, h//2\n",
    "    alpha1 = np.zeros(shape, dtype=np.float32)\n",
    "    alpha1[:,:cx] = np.linspace(blend_r, 1, cx)[np.newaxis]\n",
    "    alpha1[:,cx:] = np.linspace(1, blend_r, w-cx)[np.newaxis]\n",
    "    alpha2 = np.zeros(shape, dtype=np.float32)\n",
    "    alpha2[:cy,:] = np.linspace(blend_r, 1, cy)[:,np.newaxis]\n",
    "    alpha2[cy:,:] = np.linspace(1, blend_r, h-cy)[:,np.newaxis]\n",
    "    alpha = alpha1 * alpha2\n",
    "    zero_part = np.where(x<=0, 255, 0).astype(np.uint8)\n",
    "    zero_part = cv2.dilate(zero_part,np.ones((3,3),np.uint8),iterations=3)\n",
    "    alpha[zero_part>0] = 0\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '/home/peter0749/Downloads/Test Images/Affair'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = glob.glob(image_dir+'/*.jpg') + glob.glob(image_dir+'/*.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = list(set(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clockwise = False\n",
    "image_list.sort(reverse=not clockwise) # FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/peter0749/Downloads/Test Images/Affair/DSCN5720.JPG',\n",
       " '/home/peter0749/Downloads/Test Images/Affair/DSCN5719.JPG',\n",
       " '/home/peter0749/Downloads/Test Images/Affair/DSCN5715.JPG',\n",
       " '/home/peter0749/Downloads/Test Images/Affair/DSCN5714.JPG',\n",
       " '/home/peter0749/Downloads/Test Images/Affair/DSCN5713.JPG',\n",
       " '/home/peter0749/Downloads/Test Images/Affair/DSCN5740.JPG',\n",
       " '/home/peter0749/Downloads/Test Images/Affair/DSCN5739.JPG',\n",
       " '/home/peter0749/Downloads/Test Images/Affair/DSCN5738.JPG',\n",
       " '/home/peter0749/Downloads/Test Images/Affair/DSCN5737.JPG',\n",
       " '/home/peter0749/Downloads/Test Images/Affair/DSCN5736.JPG',\n",
       " '/home/peter0749/Downloads/Test Images/Affair/DSCN5735.JPG']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "side_n = 5\n",
    "n_imgs = len(image_list)\n",
    "n_imgs_half = n_imgs // 2\n",
    "image_list = image_list[-side_n:] + image_list[:side_n+1]\n",
    "image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_length_pix = 421.3*8\n",
    "imgs = [ cylindrical_projection(cv2.imread(path), focal_length_pix) for path in image_list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blending_map = make_blending_map(imgs[0].shape[:2], focal_length_pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(blending_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 31\n",
    "patch_size_half = patch_size//2\n",
    "sift = SIFTDescriptor(patchSize = patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_for_imgs = []\n",
    "features = []\n",
    "response_map = []\n",
    "for img in imgs:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    R = harris_response(gray)\n",
    "    R[blending_map<=0] = 0.0\n",
    "    response_map.append(R)\n",
    "    coord = detect_corner(R, num_peaks=1000, radius=20, threshold=10000000)\n",
    "    new_coord = []\n",
    "    new_feat  = []\n",
    "    # compute sift feature\n",
    "    for c in coord:\n",
    "        cc = c[0]-patch_size_half\n",
    "        rr = c[1]-patch_size_half\n",
    "        patch = gray[rr:rr+patch_size, cc:cc+patch_size]\n",
    "        if patch.shape != (patch_size, patch_size) or not np.any(patch):\n",
    "            continue\n",
    "        f = sift.describe(patch)\n",
    "        if not np.any(f): # all zero\n",
    "            continue\n",
    "        new_feat.append(np.asarray(f))\n",
    "        new_coord.append(np.asarray(c, dtype=np.int32))\n",
    "    coordinate_for_imgs.append(np.asarray(new_coord))\n",
    "    features.append(np.asarray(new_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgs[0][...,::-1])\n",
    "plt.scatter(coordinate_for_imgs[0][:,0], coordinate_for_imgs[0][:,1], s=2, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.where(response_map[0]>30000000, 255, 0), cmap='gray')\n",
    "plt.show()\n",
    "cv2.imwrite('test.png', np.where(response_map[0]>30000000, 255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_affine_matrix(src, target):\n",
    "    # src: (N, 2)\n",
    "    # target: (N, 2)\n",
    "    N = src.shape[0]\n",
    "    A = np.zeros((N*2, 6), dtype=np.float32)\n",
    "    A[::2,:2] = src\n",
    "    A[::2,2]  = 1.0\n",
    "    A[1::2,3:5] = src\n",
    "    A[1::2,5] = 1.0\n",
    "    A_pinv = np.linalg.pinv(A)\n",
    "    b = target.ravel()\n",
    "    x = np.matmul(A_pinv, b) # A.pinv * b\n",
    "    return x.reshape(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(feat_a, feat_b, ratio=0.8):\n",
    "    kd_tree = KDTree(feat_b)\n",
    "    dist, idx = kd_tree.query(feat_a, k=2)\n",
    "    final_idx = []\n",
    "    for a_idx, (d, i) in enumerate(zip(dist, idx)):\n",
    "        arg = np.argsort(d)\n",
    "        dd = d[arg]\n",
    "        ii = i[arg]\n",
    "        if dd[0]>=dd[1]*ratio:\n",
    "            continue\n",
    "        final_idx.append((a_idx, ii[0]))\n",
    "    return final_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchLR(feat_a, feat_b, ratio=0.8):\n",
    "    matched_index_a2b = match(feat_a, feat_b, ratio=ratio)\n",
    "    matched_index_b2a = match(feat_b, feat_a, ratio=ratio)\n",
    "    matched_index = list(filter(lambda x: (x[1], x[0]) in matched_index_b2a, matched_index_a2b))\n",
    "    return matched_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RANSAC(matched_pairs, coord_src, coord_tar, t=100000, threshold=5, stop_criteria=0.9):\n",
    "    src_idx, tar_idx = zip(*matched_pairs)\n",
    "    src_idx = np.asarray(src_idx, dtype=np.int32)\n",
    "    tar_idx = np.asarray(tar_idx, dtype=np.int32)\n",
    "    coord_src_matched = np.pad(coord_src[src_idx].T, ((0,1),(0,0)), mode='constant', constant_values=1.0) # (3, N)\n",
    "    coord_tar_matched = coord_tar[tar_idx].T # (2, N)\n",
    "    best_A = np.array([[1, 0, 0],[0, 1, 0]], dtype=np.float32)\n",
    "    best = 0\n",
    "    for _ in range(t):\n",
    "        sampled_pair = np.random.choice(len(src_idx), 3 , replace=False)\n",
    "        src_coord = coord_src[src_idx[sampled_pair]]\n",
    "        tar_coord = coord_tar[tar_idx[sampled_pair]]\n",
    "        A = estimate_affine_matrix(src_coord, tar_coord) # (2, 3)\n",
    "        dist = np.linalg.norm(np.matmul(A, coord_src_matched) - coord_tar_matched, ord=2, axis=0)\n",
    "        r_inliers = np.mean(dist<threshold)\n",
    "        if r_inliers > best:\n",
    "            best = r_inliers\n",
    "            best_A = A\n",
    "            if r_inliers > stop_criteria:\n",
    "                break\n",
    "    return best_A, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warpAffine(img, blending_map, A):\n",
    "    h, w = img.shape[:2]\n",
    "    end_points = np.array([[w-1,h-1,1], [w-1,0,1], [0,h-1,1]], dtype=np.float32).T # (3, N)\n",
    "    warp_end_points = np.matmul(A, end_points) # (2, N) -- xy\n",
    "    x_lim = max(int(np.ceil(np.max(warp_end_points[0])))+1, w)\n",
    "    y_lim = max(int(np.ceil(np.max(warp_end_points[1])))+1, h)\n",
    "    y_min = max(0, int(-np.min(warp_end_points[1])))\n",
    "    A[1,2] = A[1,2] + y_min\n",
    "    warp_blending_map = cv2.warpAffine(blending_map, A, (x_lim, y_lim+y_min), flags=cv2.INTER_CUBIC+cv2.WARP_FILL_OUTLIERS)\n",
    "    warp_img = cv2.warpAffine(img, A, (x_lim, y_lim+y_min), flags=cv2.INTER_CUBIC+cv2.WARP_FILL_OUTLIERS)\n",
    "    return warp_img, warp_blending_map, A, y_min\n",
    "\n",
    "def blend_imgs(img_input, img_old, blending_map_input, blending_map_old):\n",
    "    h_max = max(img_input.shape[0], img_old.shape[0])\n",
    "    w_max = max(img_input.shape[1], img_old.shape[1])\n",
    "    img_input = np.pad(img_input, ((0,h_max-img_input.shape[0]), (0,w_max-img_input.shape[1]), (0,0)), mode='constant', constant_values=0)\n",
    "    img_old = np.pad(img_old, ((0,h_max-img_old.shape[0]), (0,w_max-img_old.shape[1]), (0,0)), mode='constant', constant_values=0)\n",
    "\n",
    "    blending_map_input = np.pad(blending_map_input, ((0,h_max-blending_map_input.shape[0]), (0,w_max-blending_map_input.shape[1]), (0,0)), mode='constant', constant_values=0)\n",
    "    blending_map_old = np.pad(blending_map_old, ((0,h_max-blending_map_old.shape[0]), (0,w_max-blending_map_old.shape[1]), (0,0)), mode='constant', constant_values=0)\n",
    "\n",
    "    return img_input.astype(np.float32)*blending_map_input+img_old.astype(np.float32), blending_map_input+blending_map_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blending_map_overall = np.copy(blending_map)[...,np.newaxis]\n",
    "output = imgs[0] * blending_map_overall\n",
    "\n",
    "A_prev = np.array([[1, 0, 0], [0, 1, 0]], dtype=np.float32)\n",
    "est_x_skew = np.zeros(2, dtype=np.float32)\n",
    "coord_prev = coordinate_for_imgs[0] # (N, 2)\n",
    "feat_prev = features[0]\n",
    "for i in range(1, len(features)):\n",
    "    coord_prev_trans = np.matmul(A_prev, np.pad(coord_prev.T, ((0,1),(0,0)), mode='constant', constant_values=1.0)).T # (N, 2)\n",
    "    matched_index = matchLR(features[i], feat_prev)\n",
    "    A, inlier_frac = RANSAC(matched_index, coordinate_for_imgs[i], coord_prev_trans)\n",
    "    est_x_skew = est_x_skew + A[0,:2]\n",
    "    print(inlier_frac)\n",
    "    warp_img, warp_blending_map, A_prev, y_shift = warpAffine(imgs[i], blending_map, A)\n",
    "    warp_blending_map = warp_blending_map[...,np.newaxis]\n",
    "    output = np.pad(output, ((y_shift,0),(0,0),(0,0)), mode='constant', constant_values=0)\n",
    "    blending_map_overall = np.pad(blending_map_overall, ((y_shift,0),(0,0),(0,0)), mode='constant', constant_values=0)\n",
    "    output, blending_map_overall = blend_imgs(warp_img, output, warp_blending_map, blending_map_overall)\n",
    "    coord_prev = coordinate_for_imgs[i]\n",
    "    feat_prev = features[i]\n",
    "est_x_skew = est_x_skew / float(len(features)-1)\n",
    "print(\"Estimated slope:\", est_x_skew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_rotation_matrix(R, cx, cy):\n",
    "    d = np.array([cx, cy], dtype=np.float32).reshape(2,1)\n",
    "    trans = d + np.matmul(R, -d)\n",
    "    return np.append(R, trans, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_unit = (est_x_skew / np.linalg.norm(est_x_skew, ord=2)).astype(np.float32)\n",
    "y_unit = np.array([-x_unit[1], x_unit[0]], dtype=np.float32)\n",
    "inverse_rotation = np.stack((x_unit, y_unit)).T\n",
    "inverse_rotation = center_rotation_matrix(inverse_rotation, output.shape[1]*0.5, output.shape[0]*0.5)\n",
    "inverse_rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output / blending_map_overall\n",
    "output[blending_map_overall[...,0]<=1e-6] = 0.0\n",
    "output = np.clip(np.round(output), 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('output.jpg', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blending_map_overall_uint8 = np.clip((blending_map_overall/blending_map_overall.max())*255, 0, 255).astype(np.uint8)\n",
    "cv2.imwrite('blending_map.jpg', blending_map_overall_uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_rotation = cv2.warpAffine(output, inverse_rotation, tuple(output.shape[:2][::-1]), flags=cv2.INTER_CUBIC+cv2.WARP_FILL_OUTLIERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('fix_rotation.jpg', fix_rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(fix_rotation, cv2.COLOR_BGR2GRAY)\n",
    "mask = cv2.threshold(cv2.medianBlur(gray,3), 1.0, 255.0, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "# findContours destroys input\n",
    "contours = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n",
    "\n",
    "# sort contours by largest first (if there are more than one)\n",
    "contours = sorted(contours, key=lambda contour:len(contour), reverse=True)\n",
    "x,y,w,h = cv2.boundingRect(contours[0])\n",
    "\n",
    "cropped_img = fix_rotation[y:y+h,x:x+w]\n",
    "cv2.imwrite('cropped_output.jpg', cropped_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_panorama(img, min_width=300, min_height=300, tol=0.1):\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    mask = cv2.medianBlur(gray,5)<=0\n",
    "    \n",
    "    upper = 0\n",
    "    while np.mean(mask[upper])>tol:\n",
    "        upper += 1\n",
    "    lower = mask.shape[0]-1\n",
    "    while np.mean(mask[lower])>tol and lower-upper+1>min_height:\n",
    "        lower -= 1\n",
    "    left = 0\n",
    "    while np.mean(mask[upper:lower+1,left])>tol:\n",
    "        left += 1\n",
    "    right = mask.shape[1]-1\n",
    "    while np.mean(mask[upper:lower+1,right])>tol and right-left+1>min_width:\n",
    "        right -=1\n",
    "    return img[upper:lower+1,left:right+1], (upper, lower, left, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_rectangle, bound = crop_panorama(cropped_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('cropped.jpg', cropped_rectangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(cropped_rectangle, cv2.COLOR_BGR2GRAY)\n",
    "bin_mask = np.where(cv2.threshold(cv2.medianBlur(gray,3), 1.0, 255.0, cv2.THRESH_BINARY)[1], 1, 0)\n",
    "plt.imshow(bin_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(bin_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
